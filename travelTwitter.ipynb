{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import json\n",
    "import googlemaps # This had to be installed\n",
    "import twitter # This should already be installed (but was additional)\n",
    "import urllib.parse as urllib\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from wordcloud import WordCloud\n",
    "from math import pi\n",
    "from IPython.display import Image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bokeh Packages\n",
    "import bokeh\n",
    "from bokeh import events\n",
    "from bokeh.layouts import row, column, widgetbox, layout\n",
    "from bokeh.models.widgets import Button, TextInput, Select, Div, DataTable, TableColumn, NumberFormatter, Panel, Tabs, Paragraph\n",
    "from bokeh.models import HoverTool, ColumnDataSource, GMapOptions, CustomJS\n",
    "from bokeh.plotting import show, figure, gmap\n",
    "from bokeh.io import show, push_notebook, output_notebook, reset_output\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.application import Application\n",
    "from bokeh.models.tiles import WMTSTileSource\n",
    "from bokeh.document import Document\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.models import ColumnDataSource, Range1d, LabelSet, Label\n",
    "from bokeh.transform import cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Qitianyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Qitianyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "CREDFILE = 'OAuth.json'\n",
    "GOOGLE_MAPS_API_URL = 'http://maps.googleapis.com/maps/api/geocode/json'\n",
    "RATE_LIMIT = 15\n",
    "TRAINSET = 'data/train_data.csv'\n",
    "# DEFAULT_GEO = 'Syracuse, NY'\n",
    "PADDING = 0.1\n",
    "APP_WIDTH = 650\n",
    "APP_HEIGHT = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************ HELPER FUNCTIONS ************************************\n",
    "\n",
    "# Helper Function - Get API Keys\n",
    "def getKeys(filename):\n",
    "    with open(filename,'r') as fd:\n",
    "        keys = json.load(fd)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function - Intialize Twitter API\n",
    "def authorizeTwitter(keys):\n",
    "    api = twitter.Api(consumer_key = keys[\"consumer_key\"], \n",
    "                consumer_secret = keys[\"consumer_secret\"], \n",
    "                access_token_key = keys[\"token\"], \n",
    "                access_token_secret = keys[\"token_secret\"],\n",
    "                sleep_on_rate_limit=True)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function - Initialize Google Maps API\n",
    "def authorizeGoogle(keys):\n",
    "    gmaps = googlemaps.Client(key=keys['GoogleKey'])\n",
    "    return gmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function - Geocode Location\n",
    "def geocode(loc, api):\n",
    "    result = api.geocode(loc)\n",
    "    if (result):\n",
    "        result = result[0]['geometry']['location']\n",
    "    else:\n",
    "        result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function - Process User Query\n",
    "def processQuery(term, api):\n",
    "    raw = \"q=\" + term.replace(\" \", \"\") + \"%20%23travel%20-filter%3Aretweets\"\n",
    "    switch = 1\n",
    "    i = 0\n",
    "    tweets = list();\n",
    "    while (switch == 1):\n",
    "        \n",
    "        # Harvest tweets from Twitter API\n",
    "        results = api.GetSearch(raw_query = raw, return_json=True)\n",
    "        i += 1\n",
    "        tweets.append(results)\n",
    "        \n",
    "        # Check if there are more tweets to harvest\n",
    "        if ('next_results' in results['search_metadata'].keys()):\n",
    "            raw = results['search_metadata']['next_results']\n",
    "            temp = raw[1:].split('&q=')\n",
    "            raw = '&q=' + temp[1] + '&' + temp[0]\n",
    "        else:\n",
    "            switch = 0\n",
    "        \n",
    "        if (i == RATE_LIMIT):\n",
    "            switch = 0\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function - Extract data from twitter results\n",
    "def extractData(results):\n",
    "    labels = ['text']\n",
    "    records = list()\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(results[i]['statuses'])):\n",
    "        \n",
    "            if ('text' not in results[i]['statuses'][j].keys()):\n",
    "                text = results[i]['statuses'][j]['full_text']\n",
    "            else:\n",
    "                text = results[i]['statuses'][j]['text']\n",
    "        \n",
    "            tweet_id = results[i]['statuses'][j]['id']\n",
    "            timestamp = results[i]['statuses'][j]['created_at']\n",
    "            geo = results[i]['statuses'][j]['geo']\n",
    "            coordinates = results[i]['statuses'][j]['coordinates']\n",
    "            place = results[i]['statuses'][j]['place']\n",
    "            favorites = results[i]['statuses'][j]['favorite_count']\n",
    "            retweets = results[i]['statuses'][j]['retweet_count']\n",
    "            user_id = results[i]['statuses'][j]['user']['id']\n",
    "            screen_name = results[i]['statuses'][j]['user']['screen_name']\n",
    "            source = results[i]['statuses'][j]['source']\n",
    "            name = results[i]['statuses'][j]['user']['name']\n",
    "            location = results[i]['statuses'][j]['user']['location']\n",
    "            favourites = results[i]['statuses'][j]['user']['favourites_count']\n",
    "            followers = results[i]['statuses'][j]['user']['followers_count']\n",
    "            friends = results[i]['statuses'][j]['user']['friends_count']\n",
    "            created_at = results[i]['statuses'][j]['user']['created_at']\n",
    "            geo_enabled = results[i]['statuses'][j]['user']['geo_enabled']\n",
    "        \n",
    "            records.append([text, timestamp])\n",
    "        \n",
    "    dataset = pd.DataFrame.from_records(records, columns = labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function - Process Categorized Data\n",
    "def processTrainData():\n",
    "    rawSet = pd.read_csv(TRAINSET)\n",
    "    stops = set(stopwords.words('english'))\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tt = TweetTokenizer()\n",
    "    emotionVector = {\"empty\": -1, \"sadness\": 0, \"worry\": 0, \"neutral\": 1, \"surprise\": 2, \n",
    "                     \"love\": 3, \"happiness\": 3, \"relief\": 4, \"fun\": 5, \"enthusiasm\": 5,\n",
    "                     \"hate\": 6, \"anger\": 6, \"boredom\": 7}\n",
    "    special = re.compile('[0-9,\\,,\\:,\\/,\\=,\\&,\\;,\\%,\\$,\\@,\\#,\\%,\\^,\\*,\\(,\\),\\{,\\},\\[,\\],\\|,\\>,\\<,\\-,\\!,\\?,\\.\\'\\\"]')\n",
    "    total = 0\n",
    "    emotions = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    conditionSet = dict()\n",
    "    wordSet = dict()\n",
    "    trainList = dict()\n",
    "    \n",
    "    for index, row in rawSet.iterrows():\n",
    "        if row[\"sentiment\"] == \"empty\" or row[\"sentiment\"] == \"worry\": \n",
    "            continue\n",
    "        total += 1\n",
    "        emotions[emotionVector[row[\"sentiment\"]]] += 1\n",
    "        sentence = row[\"content\"]\n",
    "        wordList = list(set(tt.tokenize(sentence)))\n",
    "        for word in wordList:\n",
    "            word = word.strip(string.punctuation)\n",
    "            word = wnl.lemmatize(word)\n",
    "            word = word.lower()\n",
    "            if special.search(word) == None and word not in stops and len(word) > 1:\n",
    "                if word not in trainList:\n",
    "                    trainList[word] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "                trainList[word][emotionVector[row[\"sentiment\"]]] += 1\n",
    "    trainList = sorted(trainList.items(),key = lambda x: (x[1][0] + x[1][1] + x[1][2] + x[1][3] + x[1][4] + x[1][5] + x[1][6] + x[1][7]), reverse = True)\n",
    "    trainList = trainList[:10000]\n",
    "    for word in trainList:\n",
    "        conditionSet[word[0]] = word[1]\n",
    "        wordSet[word[0]] = (word[1][0] + word[1][1] + word[1][2] + word[1][3] + word[1][4] + word[1][5] + word[1][6] + word[1][7]) / total\n",
    "    \n",
    "    for (key, value) in conditionSet.items():\n",
    "        for i in range(8):\n",
    "            value[i] = value[i] / emotions[i]\n",
    "    for i in range(8):\n",
    "        emotions[i] = emotions[i] / total\n",
    "#     emotions[0] /= 10\n",
    "#     emotions[3] *= 10\n",
    "    return (conditionSet, wordSet, emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(wordList, wordDup, conditionSet, wordSet, emotionSet):\n",
    "    result = []\n",
    "    actual = []\n",
    "    actualDup = []\n",
    "    for word in wordList:\n",
    "        if word in conditionSet.keys():\n",
    "            actual.append(word)\n",
    "    if len(actual) < 2:\n",
    "        return (-1, None)\n",
    "    for word in wordDup:\n",
    "        if word in conditionSet.keys():\n",
    "            actualDup.append(word)\n",
    "    general = 1.0\n",
    "    for word in actual:\n",
    "        general *= wordSet[word]\n",
    "    for i in range(8):\n",
    "        condition = emotionSet[i]\n",
    "        for word in actual:\n",
    "            condition *= conditionSet[word][i]\n",
    "        result.append(condition / general)\n",
    "    res = 0.0\n",
    "    pos = -1\n",
    "    for i in range(8):\n",
    "        if result[i] > res:\n",
    "            res = result[i]\n",
    "            pos = i\n",
    "    return (pos, actualDup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer()\n",
    "tt = TweetTokenizer()\n",
    "special = re.compile('[0-9,\\,,\\:,\\/,\\=,\\&,\\;,\\%,\\$,\\@,\\#,\\%,\\^,\\*,\\(,\\),\\{,\\},\\[,\\],\\|,\\>,\\<,\\-,\\!,\\?,\\.\\'\\\"]')\n",
    "def getQueryWordList(word):\n",
    "    wordListDup = tt.tokenize(word)\n",
    "    wordList = list(set(tt.tokenize(word)))\n",
    "    resultDup = []\n",
    "    result = []\n",
    "    for word in wordList:\n",
    "        word = word.strip(string.punctuation)\n",
    "        word = wnl.lemmatize(word)\n",
    "        word = word.lower()\n",
    "        if special.search(word) == None and word not in stops and len(word) > 1:\n",
    "            result.append(word)\n",
    "    for word in wordListDup:\n",
    "        word = word.strip(string.punctuation)\n",
    "        word = wnl.lemmatize(word)\n",
    "        word = word.lower()\n",
    "        if special.search(word) == None and word not in stops and len(word) > 1:\n",
    "            resultDup.append(word)\n",
    "    return (result, resultDup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************ MAIN PROGRAM ************************************\n",
    "\n",
    "# PHASE I - Initialize\n",
    "\n",
    "# Initialize APIs\n",
    "keys = getKeys(CREDFILE)\n",
    "tAPI = authorizeTwitter(keys)\n",
    "gAPI = authorizeGoogle(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(conditionSet, wordSet, emotionSet) = processTrainData()\n",
    "emotionVectorReverse = {0: \"sadness\", 1: \"neutral\", 2: \"surprise\", 3: \"happiness\", 4: \"relief\", 5: \"fun\", 6: \"anger\", 7: \"bordom\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmotions(tweetList):\n",
    "    emotions = {\"sadness\": 0, \"neutral\": 0, \"surprise\": 0, \"happiness\": 0, \"relief\": 0, \"fun\": 0, \"anger\": 0, \"bordom\": 0}\n",
    "    emotionVocab = {\"sadness\": [], \"neutral\": [], \"surprise\": [], \"happiness\": [], \n",
    "                    \"relief\": [], \"fun\": [], \"anger\": [], \"bordom\": []}\n",
    "    emotionTweets = dict()\n",
    "    for word in tweetList:\n",
    "        (words, wordsDup) = getQueryWordList(word)\n",
    "        (emotionResult, emotionWords) = classify(words, wordsDup, conditionSet, wordSet, emotionSet)\n",
    "        if emotionResult != -1:\n",
    "            emotions[emotionVectorReverse[emotionResult]] += 1\n",
    "            emotionTweets[word] = emotionVectorReverse[emotionResult]\n",
    "            for emotionWord in emotionWords:\n",
    "                emotionVocab[emotionVectorReverse[emotionResult]].append(emotionWord)\n",
    "    return (emotions, emotionVocab, emotionTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printWordClouds(wordList, name):\n",
    "    wordcloud = WordCloud(background_color='white',\n",
    "                           width=1000,\n",
    "                           height=600, \n",
    "                           margin=0\n",
    "                         ).generate(wordList)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"data/\" + name + \".png\")\n",
    "    \n",
    "def getWordClouds(emotionVocab):\n",
    "    dt = time.time()\n",
    "    timeArray = time.localtime(dt)\n",
    "    otherStyleTime = time.strftime(\"%Y_%m_%d_%H_%M_%S\", timeArray)\n",
    "    possible = dict()\n",
    "    allWords = \"\"\n",
    "    for (key, value) in emotionVocab.items():\n",
    "        if len(value) != 0:\n",
    "            possible[key] = otherStyleTime + \"_\" + key\n",
    "            tmp = \"\"\n",
    "            for word in value:\n",
    "                tmp += \" \"\n",
    "                tmp += word\n",
    "            printWordClouds(tmp, key)\n",
    "            allWords += (tmp + \" \")\n",
    "    printWordClouds(allWords, otherStyleTime + \"_\" + \"all\")\n",
    "    possible[\"all\"] = (otherStyleTime + \"_\" + \"all\")\n",
    "    return possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds = processQuery(\"yellowstone\", tAPI)\n",
    "data = extractData(feeds)[\"text\"]\n",
    "(emotionData, emotionVocab, emotionTweets) = getEmotions(data)\n",
    "possibleImages = getWordClouds(emotionVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of plotting pie chart\n",
    "def plotPieChart(dataSet):\n",
    "    data = pd.Series(dataSet).reset_index(name='value').rename(columns={'index':'sentiment'})\n",
    "    data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "    data['color'] = Category20c[len(dataSet)]\n",
    "    data['percent'] = data['value'] / sum(dataSet.values()) * 100\n",
    "\n",
    "    p = figure(plot_height=350, title=\"Sentiment Distribution\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@sentiment: @percent{0.2f} %\", x_range=(-0.5, 1.0))\n",
    "\n",
    "    p.wedge(x=0, y=1, radius=0.4,\n",
    "            start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "            line_color=\"white\", fill_color='color', legend='sentiment', source=data)\n",
    "\n",
    "    p.axis.axis_label=None\n",
    "    p.axis.visible=False\n",
    "    p.grid.grid_line_color = None\n",
    "#     show(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTweets(tweets, condition):\n",
    "    if condition != \"all\":\n",
    "        tmp = dict()\n",
    "        for (key, value) in tweets.items():\n",
    "            if value == condition:\n",
    "                tmp[key] = value\n",
    "#         tweets.clear()\n",
    "        tweets = tmp\n",
    "    dataRaw = {\"Tweet\": list(tweets.keys()), \"Emotion\": list(tweets.values())}\n",
    "    data = pd.DataFrame.from_records(dataRaw, columns=[\"Tweet\", \"Emotion\"])\n",
    "    cols = [TableColumn(field='Tweet', title='Tweet'),\n",
    "            TableColumn(field='Emotion', title='Emotion'),]\n",
    "    dt = DataTable(source=ColumnDataSource(data), columns=cols, width=APP_WIDTH, height=APP_HEIGHT)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of plotting informative words\n",
    "def plotTagCloud(dataset):\n",
    "    p = figure(plot_width=750, plot_height=500, toolbar_sticky=True)\n",
    "    p.line([-6,6], [0,0], line_width=4)\n",
    "    p.line([0,0], [-6,6], line_width=4)\n",
    "    source = ColumnDataSource(data=dict(x=[-6, 6, 0, 0],\n",
    "                                    y=[0, 0, 6, -6],\n",
    "                                    names=['unpleasant', 'pleasant', 'positive', 'negtive']))\n",
    "    p.scatter(x='x', y='y', size=8, source=source)\n",
    "    labels = LabelSet(x='x', y='y', text='names', level='glyph',\n",
    "              x_offset=2, y_offset=2, source=source, render_mode='canvas')\n",
    "    p.add_layout(labels)\n",
    "    p.axis.axis_label=None\n",
    "    p.axis.visible=False\n",
    "    p.grid.grid_line_color = None\n",
    "#     show(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPanel(dataset, imageNames, condition, tweets):\n",
    "\n",
    "    # Spacing ELements\n",
    "    space1 = Div(text='div1', sizing_mode='scale_height', width=75)\n",
    "    space2 = Div(text='div2', sizing_mode='scale_height', width=70)\n",
    "    space3 = Div(text='div3', sizing_mode='scale_width', height=25)\n",
    "\n",
    "    # Content for Panel 1\n",
    "    most = \"\"\n",
    "    maxi = 0\n",
    "    for (key, value) in dataset.items():\n",
    "        if value > maxi:\n",
    "            most = key\n",
    "            maxi = value\n",
    "    header1 = Div(text='<div align=\"Left\" style=\"display:block\"> \\\n",
    "                            <h3>People\\'s emotion of this spot<h3> \\\n",
    "                            <span style=\"display:block\">Most people feel </span> \\\n",
    "                            <br/>' + \\\n",
    "                            '<span style=\"color: blue\">' + most + '</span> \\\n",
    "                        </div>', width=700)\n",
    "    \n",
    "    pieChart = row(plotPieChart(dataset), height = 600, width = APP_WIDTH)\n",
    "    \n",
    "    # Content for Panel 2\n",
    "    header2 = Div(text='<div align=\"Left\" style=\"display:block\"><h3>Harvested tweets and sentiments<h3><br></div>', width=700)\n",
    "    select = imageNames[\"all\"]\n",
    "    if condition in imageNames.keys():\n",
    "        select = imageNames[condition]\n",
    "    dataTable = row(plotTweets(tweets, condition), height = 600, width = APP_WIDTH)\n",
    "    \n",
    "    # Content for Panel 3\n",
    "    header3 = Div(text='<div align=\"Left\" style=\"display:block\"><h3>Word cloud for selected sentiment<h3><br></div>', width=700)\n",
    "    imgUrl = \"http://localhost:8888/files/data/\" + select + \".png\"\n",
    "    div = Div(text=\"<div style='margin:-10px'> \\\n",
    "                        <img src=\" + imgUrl + \">\" + \\\n",
    "                   \"</div>\", width=1000)\n",
    "\n",
    "    # Layout Panels\n",
    "    tab1 = Panel(child=column([header1,pieChart], height=APP_HEIGHT, width=APP_WIDTH), title='General Analyze Result')\n",
    "    tab2 = Panel(child=column([header2, dataTable], height=APP_HEIGHT, width=APP_WIDTH), title='Tweets')\n",
    "    tab3 = Panel(child=column([header3, div], height=APP_HEIGHT, width=APP_WIDTH), title='Word Cloud')\n",
    "    tabs = Tabs(tabs=[tab1, tab2, tab3])\n",
    "    return tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the modification of HTML content\n",
    "def modify_doc(doc):\n",
    "    \n",
    "    # Create the main plot\n",
    "    def dashboard(mode, data, imageName, condition, emotionTweets):\n",
    "        \n",
    "        # Spacing\n",
    "        spacing = Div(text='', sizing_mode='scale_width', height=50)\n",
    "        \n",
    "        # Initial Display\n",
    "        if (mode == 'initial'):\n",
    "            intro = Div(text='<div align=\"center\" style=\"display:block\"> \\\n",
    "                                    <h2>Welcome to TravelTwitter!</h2> \\\n",
    "                                    <h3>Author: Tianyu Qi, Chang Liu, Bohao Li</h3> \\\n",
    "                              </div>', width=700)\n",
    "            p = column([spacing, intro])\n",
    "        \n",
    "        # Display results of Request\n",
    "        elif (mode == 'results'):\n",
    "            p = plotPanel(data, imageName, condition, emotionTweets)\n",
    "        \n",
    "        return p\n",
    "\n",
    "    # Handle Errors\n",
    "    def error(code):\n",
    "        \n",
    "        # Spacing\n",
    "        br = Div(text='', sizing_mode='scale_width', height=50)\n",
    "        \n",
    "        # No results returned from Twitter search\n",
    "        if (code == 'SEARCH'):\n",
    "            err = Div(text='<div align=\"center\" style=\"display:block\"><h2>Error: No Results Found</h2></div>', width=APP_WIDTH)\n",
    "            p = column([br, err])\n",
    "        elif (code == 'INPUT'):\n",
    "            err = Div(text='<div align=\"center\" style=\"display:block\"><h2>Error: Check your input</h2></div>', width=APP_WIDTH)\n",
    "            p = column([br, err])\n",
    "        return p\n",
    "    \n",
    "    def status(code):\n",
    "        \n",
    "        # Spacing\n",
    "        space = Div(text='', sizing_mode='scale_width', height=50)\n",
    "\n",
    "        # Harvesting data from Twitter\n",
    "        if (code == 'HARVEST'):\n",
    "            message = Div(text='<div align=\"center\" style=\"display:block\"> \\\n",
    "                                      <h3>Getting Tweets...</h3> \\\n",
    "                                      <br><br> \\\n",
    "                                      <iframe src=\"https://www.alarisworld.com/images/loading.gif\" \\\n",
    "                                          width=\"200\" height=\"200\" frameBorder=\"0\"> \\\n",
    "                                      </iframe> \\\n",
    "                                </div>', width=APP_WIDTH)\n",
    "            p = column([space, message])\n",
    "        \n",
    "        # Classifying sentiment of Tweets\n",
    "        elif (code == 'CLASSIFY'):\n",
    "            message = Div(text='<div align=\"center\" style=\"display:block\"> \\\n",
    "                                      <h3>Classifying...</h3> \\\n",
    "                                      <br><br> \\\n",
    "                                      <iframe src=\"https://www.alarisworld.com/images/loading.gif\" \\\n",
    "                                          width=\"200\" height=\"200\" frameBorder=\"0\"> \\\n",
    "                                      </iframe> \\\n",
    "                                </div>', width=APP_WIDTH)\n",
    "            p = column([space, message])\n",
    "            \n",
    "        # Generating plots to display results\n",
    "        elif (code == 'PLOT'):\n",
    "            message = Div(text='<div align=\"center\" style=\"display:block\"> \\\n",
    "                                      <h3>Ploting...</h3> \\\n",
    "                                      <br><br> \\\n",
    "                                      <iframe src=\"https://www.alarisworld.com/images/loading.gif\" \\\n",
    "                                          width=\"200\" height=\"200\" frameBorder=\"0\"> \\\n",
    "                                      </iframe> \\\n",
    "                                </div>', width=APP_WIDTH)\n",
    "            p = column([space, message])\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    # Update the plot\n",
    "    def update():\n",
    "        \n",
    "        # Location Input\n",
    "        locName = GUI.children[0].children[1].value\n",
    "        condition = GUI.children[0].children[4].value\n",
    "        \n",
    "        if locName=='':\n",
    "            GUI.children[2] = error('INPUT')\n",
    "            return\n",
    "        \n",
    "        GUI.children[2] = status('HARVEST')\n",
    "        time.sleep(2)\n",
    "        feeds = processQuery(locName, tAPI)\n",
    "        data = extractData(feeds)[\"text\"]\n",
    "        \n",
    "        GUI.children[2] = status('CLASSIFY')\n",
    "        time.sleep(1)\n",
    "        (emotionData, emotionVocab, emotionTweets) = getEmotions(data)\n",
    "        possibleImages = getWordClouds(emotionVocab)\n",
    "        \n",
    "        # Display Results\n",
    "        GUI.children[2] = status('PLOT')\n",
    "        time.sleep(2)\n",
    "        GUI.children[2] = dashboard('results', emotionData, possibleImages, condition, emotionTweets)\n",
    "        # Reset Menu\n",
    "        GUI.children[0] = buildMenu()\n",
    "        \n",
    "    # Construct Menu\n",
    "    def buildMenu():\n",
    "    \n",
    "        # Buttons\n",
    "        submit = Button(label='Submit', button_type='primary')\n",
    "        submit.on_click(update)\n",
    "        conditionSubmit = Button(label='Condition', button_type='primary')\n",
    "        conditionSubmit.on_click(update)\n",
    "        \n",
    "        # Location Input\n",
    "        inputLabel = Div(text='<h3>Location Input</h3>', height=20)\n",
    "        spotName = TextInput(value=\"\", title='',sizing_mode='scale_width')\n",
    "        \n",
    "        # Condition Input\n",
    "        conditionLabel = Div(text='<h3>Condition Input</h3>', height=20)\n",
    "        select = Select(title=\"Sentiment\", value=\"all\", options=[\"all\", \"sadness\", \"neutral\", \"surprise\", \"happiness\", \n",
    "                                                                \"relief\", \"fun\", \"anger\", \"bordom\"])\n",
    "        \n",
    "        # Input Control\n",
    "        menu = widgetbox([inputLabel, spotName, submit, conditionLabel, select, conditionSubmit], width=200)\n",
    "        return menu\n",
    "    seperator = Div(text='', sizing_mode='scale_height', width=75)\n",
    "    GUI = row([buildMenu(), seperator, dashboard('initial', None, None, None, None)], width=900, height = APP_HEIGHT)\n",
    "    doc.add_root(GUI)\n",
    "handler = FunctionHandler(modify_doc)\n",
    "app = Application(handler)\n",
    "doc = app.create_document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"ccaf811f-7e23-47f6-a9cd-fe63a48b6267\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"ccaf811f-7e23-47f6-a9cd-fe63a48b6267\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"ccaf811f-7e23-47f6-a9cd-fe63a48b6267\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ccaf811f-7e23-47f6-a9cd-fe63a48b6267' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"ccaf811f-7e23-47f6-a9cd-fe63a48b6267\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"ccaf811f-7e23-47f6-a9cd-fe63a48b6267\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"ccaf811f-7e23-47f6-a9cd-fe63a48b6267\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ccaf811f-7e23-47f6-a9cd-fe63a48b6267' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"ccaf811f-7e23-47f6-a9cd-fe63a48b6267\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "\n",
       "<script src=\"http://localhost:59514/autoload.js?bokeh-autoload-element=cccaac7d-d07a-4db0-895a-e956d816197e&bokeh-absolute-url=http://localhost:59514&resources=none\" id=\"cccaac7d-d07a-4db0-895a-e956d816197e\"></script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "6360e46b3fa143ed826f5371ed95aa84"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reset_output()\n",
    "output_notebook()\n",
    "show(app, notebook_url=\"localhost:8888\", notebook_handle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
